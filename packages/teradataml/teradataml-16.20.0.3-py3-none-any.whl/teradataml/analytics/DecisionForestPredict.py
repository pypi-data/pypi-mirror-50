#!/usr/bin/python
# ################################################################## 
# 
# Copyright 2018 Teradata. All rights reserved.
# TERADATA CONFIDENTIAL AND TRADE SECRET
# 
# Primary Owner: Pankaj Purandare (pankajvinod.purandare@teradata.com)
# Secondary Owner: Mounika Kotha (mounika.kotha@teradata.com)
# 
# Version: 1.2
# Function Version: 1.13
# 
# ################################################################## 

from teradataml.common.wrapper_utils import AnalyticsWrapperUtils
from teradataml.common.utils import UtilFuncs
from teradataml.context.context import *
from teradataml.dataframe.dataframe import DataFrame
from teradataml.common.aed_utils import AedUtils
from teradataml.analytics.analytic_query_generator import AnalyticQueryGenerator
from teradataml.common.exceptions import TeradataMlException
from teradataml.common.messages import Messages
from teradataml.common.messagecodes import MessageCodes
from teradataml.common.constants import TeradataConstants
from teradataml.dataframe.dataframe_utils import DataFrameUtils as df_utils
from teradataml.options.display import display
from teradataml.analytics.mle.DecisionForest import DecisionForest

from teradataml.common.utils import package_deprecation

@package_deprecation('16.20.00.02', 'teradataml.analytics.sqle')
class DecisionForestPredict:
    
    def __init__(self,
        object = None,
        newdata = None,
        id_column = None,
        detailed = False,
        terms = None) :
        """
        DESCRIPTION:
            The DecisionForestPredict uses the model generated by the
            DecisionForest to generate predictions on a response variable
            for a test set of data. The model can be stored in either a
            teradataml DataFrame or a DecisionForest object.
        
        
        PARAMETERS:
            object:
                Required Argument.
                Specifies the teradataml DataFrame containing the model data
                or instance of DecisionForest, which contains the model.
            
            newdata:
                Required Argument.
                Specifies the teradataml DataFrame containing the input test data.
            
            id_column:
                Required Argument.
                Specifies a column containing a unique identifier for each test point 
                in the test set.
                Types: str
            
            detailed:
                Optional Argument.
                Specifies whether to output detailed information about the forest 
                trees; that is, the decision tree and the specific tree information, 
                including task index and tree index for each tree. 
                Default Value: False
                Types: bool
            
            terms:
                Optional Argument.
                Specifies the names of the input columns to copy to the output table.
                Types: str OR list of Strings (str)
        
        RETURNS:
            Instance of DecisionForestPredict.
            Output teradataml DataFrames can be accessed using attribute
            references, such as DecisionForestPredictObj.<attribute_name>.
            Output teradataml DataFrame attribute name is:
                result
        
        
        RAISES:
            TeradataMlException
        
        
        EXAMPLES:
            # Load the data to run the example
            load_example_data("decisionforestpredict", ["housing_train","housing_test"])
            
            # Create teradataml DataFrame objects.
            housing_test = DataFrame.from_table("housing_test")
            housing_train = DataFrame.from_table("housing_train")

            # Example 1 -
            # First train the data, i.e., create a decision forest Model
            formula = "homestyle ~ driveway + recroom + fullbase + gashw + airco + prefarea + price \
                      + lotsize + bedrooms + bathrms + stories + garagepl"
            rft_model = DecisionForest(data=housing_train,
                                      formula = formula,
                                      tree_type="classification",
                                      ntree=50,
                                      tree_size=100,
                                      nodesize=1,
                                      variance=0.0,
                                      max_depth=12,
                                      maxnum_categorical=20,
                                      mtry=3,
                                      mtry_seed=100,
                                      seed=100
                                      )

            # Run predict on the output of decision forest
            decision_forest_predict_out = DecisionForestPredict(object = rft_model,
                                                                newdata = housing_test,
                                                                id_column = "sn",
                                                                detailed = False,
                                                                terms = ["homestyle"]
                                                                )

            # Print the results
            decision_forest_predict_out.result
        
        """
        self.object  = object 
        self.newdata  = newdata 
        self.id_column  = id_column 
        self.detailed  = detailed 
        self.terms  = terms 
        
        # Create TeradataPyWrapperUtils instance which contains validation functions.
        self.__awu = AnalyticsWrapperUtils()
        self.__aed_utils = AedUtils()
        
        # Create argument information matrix to do parameter checking
        self.__arg_info_matrix = []
        self.__arg_info_matrix.append(["object", self.object, False, "DataFrame"])
        self.__arg_info_matrix.append(["newdata", self.newdata, False, "DataFrame"])
        self.__arg_info_matrix.append(["id_column", self.id_column, False, "str"])
        self.__arg_info_matrix.append(["detailed", self.detailed, True, "bool"])
        self.__arg_info_matrix.append(["terms", self.terms, True, "str"])
        
        # Perform the function validations
        self.__validate()
        # Generate the ML query
        self.__form_tdml_query()
        # Execute ML query
        self.__execute()
        
    def __validate(self) :
        """
        Function to validate sqlmr function arguments, which verifies missing
        arguments, input argument and table types. Also processes the 
        argument values.
        """
        # Make sure that a non-NULL value has been supplied for all mandatory arguments
        self.__awu._validate_missing_required_arguments(self.__arg_info_matrix)
        
        # Make sure that a non-NULL value has been supplied correct type of argument
        self.__awu._validate_argument_types(self.__arg_info_matrix)
        
        # Check to make sure input table types are strings or data frame objects or of valid type.
        self.__awu._validate_input_table_datatype(self.newdata, "newdata", None)
        self.__awu._validate_input_table_datatype(self.object, "object", DecisionForest)
        
        # Check whether the input columns passed to the argument are not empty.
        # Also check whether the input columns passed to the argument valid or not.
        self.__awu._validate_input_columns_not_empty(self.id_column, "id_column")
        self.__awu._validate_dataframe_has_argument_columns(self.id_column, "id_column", self.newdata, "newdata")
        
        self.__awu._validate_input_columns_not_empty(self.terms, "terms")
        self.__awu._validate_dataframe_has_argument_columns(self.terms, "terms", self.newdata, "newdata")
        
        
    def __form_tdml_query(self) :
        """
        Function to generate the analytical function queries. The function defines
        variables and list of arguments required to form the query.
        """
        if isinstance(self.object, DecisionForest):
            self.object = self.object._mlresults[0]
        
        # Output table arguments list
        self.__func_output_args_sql_names = []
        self.__func_output_args = []
        
        # Generate lists for rest of the function arguments
        self.__func_other_arg_sql_names = []
        self.__func_other_args = []
        self.__func_other_arg_json_datatypes = []
        
        self.__func_other_arg_sql_names.append("IdColumn")
        self.__func_other_args.append(UtilFuncs._teradata_collapse_arglist(self.id_column,"'"))
        self.__func_other_arg_json_datatypes.append("COLUMNS")

        if self.terms is not None:
            self.__func_other_arg_sql_names.append("Accumulate")
            self.__func_other_args.append(UtilFuncs._teradata_collapse_arglist(self.terms,"'"))
            self.__func_other_arg_json_datatypes.append("COLUMNS")
        
        if self.detailed is not None and self.detailed != False:
            self.__func_other_arg_sql_names.append("Detailed")
            self.__func_other_args.append(UtilFuncs._teradata_collapse_arglist(self.detailed,"'"))
            self.__func_other_arg_json_datatypes.append("BOOLEAN")
        
        
        # Declare empty lists to hold input table information.
        self.__func_input_arg_sql_names = []
        self.__func_input_table_view_query = []
        self.__func_input_dataframe_type = []
        self.__func_input_distribution = []
        self.__func_input_partition_by_cols = []
        self.__func_input_order_by_cols = []
        
        # Process newdata
        self.__table_ref = self.__awu._teradata_on_clause_from_dataframe(self.newdata, False)
        self.__func_input_distribution.append("FACT")
        self.__func_input_arg_sql_names.append("input")
        self.__func_input_table_view_query.append(self.__table_ref["ref"])
        self.__func_input_dataframe_type.append(self.__table_ref["ref_type"])
        self.__func_input_partition_by_cols.append("ANY")
        self.__func_input_order_by_cols.append("NA_character_")
        
        # Process object
        self.__table_ref = self.__awu._teradata_on_clause_from_dataframe(self.object, False)
        self.__func_input_distribution.append("DIMENSION")
        self.__func_input_arg_sql_names.append("ModelTable")
        self.__func_input_table_view_query.append(self.__table_ref["ref"])
        self.__func_input_dataframe_type.append(self.__table_ref["ref_type"])
        self.__func_input_partition_by_cols.append("NA_character_")
        self.__func_input_order_by_cols.append("NA_character_")
        
        function_name = "DecisionForestPredict"
        # Create instance to generate SQLMR.
        aqg_obj = AnalyticQueryGenerator(function_name 
                ,self.__func_input_arg_sql_names 
                ,self.__func_input_table_view_query 
                ,self.__func_input_dataframe_type 
                ,self.__func_input_distribution 
                ,self.__func_input_partition_by_cols 
                ,self.__func_input_order_by_cols 
                ,self.__func_other_arg_sql_names 
                ,self.__func_other_args 
                ,self.__func_other_arg_json_datatypes 
                ,self.__func_output_args_sql_names 
                ,self.__func_output_args)
        # Invoke call to SQL-MR generation.
        self.sqlmr_query = aqg_obj._gen_sqlmr_select_stmt_sql()
        
        # Print SQL-MR query if requested to do so.
        if display.print_sqlmr_query:
            print(self.sqlmr_query)
        
    def __execute(self) :
        """
        Function to generate AED nodes for output tables.
        This makes a call aed_ml_query() and then output table dataframes are created.
        """
        # Generate STDOUT table name and add it to the output table list.
        sqlmr_stdout_temp_tablename = UtilFuncs._generate_temp_table_name(prefix="td_sqlmr_out_",
                                                                          use_default_database=True, gc_on_quit=True,
                                                                          quote=False)
        try:
            UtilFuncs._create_view(sqlmr_stdout_temp_tablename, self.sqlmr_query)
        except Exception as emsg:
            raise TeradataMlException(Messages.get_message(MessageCodes.TDMLDF_EXEC_SQL_FAILED, str(emsg)),
                                      MessageCodes.TDMLDF_EXEC_SQL_FAILED)

        # Update output table data frames.
        self._mlresults = []
        self.result = self.__awu._create_data_set_object(
            df_input=UtilFuncs._extract_table_name(sqlmr_stdout_temp_tablename), source_type="table",
            database_name=UtilFuncs._extract_db_name(sqlmr_stdout_temp_tablename))
        self._mlresults.append(self.result)

    def __repr__(self) :
        """
        Returns the string representation for a DecisionForestPredict class instance.
        """
        repr_string="############ STDOUT Output ############"
        repr_string = "{}\n\n{}".format(repr_string,self.result)
        return repr_string
        
