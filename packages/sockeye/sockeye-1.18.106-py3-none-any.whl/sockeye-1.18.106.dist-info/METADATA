Metadata-Version: 2.1
Name: sockeye
Version: 1.18.106
Summary: Sequence-to-Sequence framework for Neural Machine Translation
Home-page: https://github.com/awslabs/sockeye
Author: Amazon
Author-email: sockeye-dev@amazon.com
Maintainer-email: sockeye-dev@amazon.com
License: Apache License 2.0
Platform: UNKNOWN
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3 :: Only
Requires-Python: >=3
Description-Content-Type: text/markdown
Requires-Dist: pyyaml (>=5.1)
Requires-Dist: mxnet-mkl (==1.4.1)
Requires-Dist: numpy (>=1.14)
Requires-Dist: typing
Requires-Dist: portalocker
Requires-Dist: sacrebleu (==1.3.6)
Provides-Extra: dev
Requires-Dist: pytest ; extra == 'dev'
Requires-Dist: pytest-cov (<2.6.0) ; extra == 'dev'
Requires-Dist: pillow ; extra == 'dev'
Requires-Dist: check-manifest ; extra == 'dev'
Requires-Dist: matplotlib ; extra == 'dev'
Requires-Dist: mypy (==0.610) ; extra == 'dev'
Requires-Dist: pylint (==2.3.0) ; extra == 'dev'
Requires-Dist: setuptools (>=38.6.0) ; extra == 'dev'
Requires-Dist: twine (>=1.11.0) ; extra == 'dev'
Requires-Dist: wheel (>=0.31.0) ; extra == 'dev'
Provides-Extra: optional
Requires-Dist: mxboard ; extra == 'optional'
Requires-Dist: matplotlib ; extra == 'optional'

# Sockeye

[![PyPI version](https://badge.fury.io/py/sockeye.svg)](https://badge.fury.io/py/sockeye)
[![GitHub license](https://img.shields.io/github/license/awslabs/sockeye.svg)](https://github.com/awslabs/sockeye/blob/master/LICENSE)
[![GitHub issues](https://img.shields.io/github/issues/awslabs/sockeye.svg)](https://github.com/awslabs/sockeye/issues)
[![Build Status](https://travis-ci.org/awslabs/sockeye.svg?branch=master)](https://travis-ci.org/awslabs/sockeye)
[![Documentation Status](https://readthedocs.org/projects/sockeye/badge/?version=latest)](http://sockeye.readthedocs.io/en/latest/?badge=latest)

This package contains the Sockeye project, a sequence-to-sequence framework for Neural Machine Translation based on Apache MXNet (Incubating).
It implements state-of-the-art encoder-decoder architectures, such as:

- Deep Recurrent Neural Networks with Attention [[Bahdanau, '14](https://arxiv.org/abs/1409.0473)]
- Transformer Models with self-attention [[Vaswani et al, '17](https://arxiv.org/abs/1706.03762)]
- Fully convolutional sequence-to-sequence models [[Gehring et al, '17](https://arxiv.org/abs/1705.03122)]

In addition, it provides an experimental [image-to-description module](https://github.com/awslabs/sockeye/tree/master/sockeye/image_captioning) that can be used for image captioning.
Recent developments and changes are tracked in our [CHANGELOG](https://github.com/awslabs/sockeye/blob/master/CHANGELOG.md).

If you have any questions or discover problems, please [file an issue](https://github.com/awslabs/sockeye/issues/new).
You can also send questions to *sockeye-dev-at-amazon-dot-com*.

## Documentation

For information on how to use Sockeye, please visit [our documentation](https://awslabs.github.io/sockeye/).
Developers may be interested in our [developer guidelines](https://awslabs.github.io/sockeye/development.html).

## Citation

For technical information about Sockeye, see our paper on the arXiv ([BibTeX](sockeye.bib)):

> Felix Hieber, Tobias Domhan, Michael Denkowski, David Vilar, Artem Sokolov, Ann Clifton and Matt Post. 2017.
> [Sockeye: A Toolkit for Neural Machine Translation](https://arxiv.org/abs/1712.05690). ArXiv e-prints.




