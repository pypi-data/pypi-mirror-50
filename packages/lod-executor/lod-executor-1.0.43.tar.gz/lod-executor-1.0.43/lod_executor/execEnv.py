import collections
import datetime
import dateutil.parser
import docker
import json
import os
import requests
from requests_toolbelt.adapters.ssl import SSLAdapter
import shutil
import ssl
import sys
import threading
import time

from .exceptions import InvalidParamsException, BenignException, ServersideProgrammingError
from . import basics
from . import utilities


###############################################################################################
# helper classes
###############################################################################################


class CurrentlyDisplayedStatus:
    """
    Context manager for changing the current status of an ExecEnv object.
    """
    def __init__(self, exec_env, msg):
        self.exec_env = exec_env
        self.msg = msg
    def __enter__(self):
        with self.exec_env.lock:
            self.old_msg = self.exec_env.current_status_message
            self.exec_env.current_status_message = self.msg
    def __exit__(self, etype, value, traceback):
        with self.exec_env.lock:
            self.exec_env.current_status_message = self.old_msg


###############################################################################################
# helper functions
###############################################################################################


_SOURCE_OF_TRUTH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'TRUTH.txt')
_truth = None
def _get_truth():
    """
    load constants from a file that is autogenerated from the outside when this module is compiled.
    This is a convenient way to share constants between different applications during development.
    Uses a cache.
    """
    global _truth
    if _truth is None:
        with open(_SOURCE_OF_TRUTH, 'r') as f:
            _truth = json.load(f)
    return _truth


###############################################################################################
# helper functions - folders
###############################################################################################


def get_step_folder(execution_id, step_num):
    """
    return the path representing the folder of a given step of a given execution
    """
    return os.path.join(_the_manager.config['exec_env_root_folder'], 'exec%d/step%d' % (execution_id, step_num))


def get_step_explanation_file_in(execution_id, step_num):
    """
    return the path to the txt file that describes the input used for an execution step, which can be read by the program being executed.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'in.txt')


def get_step_explanation_file_out(execution_id, step_num):
    """
    return the path to the txt file that describes the output generated by an execution step, which should be created by the program being executed.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'out.txt')


def get_step_file_in(execution_id, step_num, arg_index):
    """
    return the path to the file of a given object used as input in a given step of a given execution
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'in_%s' % (arg_index,))


def get_step_file_out(execution_id, step_num, file_index):
    """
    return the path to the file of a given object used as output in a given step of a given execution
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'out_%d' % (file_index,))


def get_step_file_error(execution_id, step_num):
    """
    return the path to the error file created by a program execution, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'error.txt')


def get_step_file_parsing_error(execution_id, step_num):
    """
    return the path to the error file created after a program execution if the parsing of that step's output failed, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'output_parsing_error.txt')


def get_step_file_log(execution_id, step_num):
    """
    return the path to the lig file of a program execution, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'log.txt')


###############################################################################################
# helper functions - Docker
###############################################################################################


_docker_client = None
def get_docker_client(version='auto'):
    global _docker_client
    if _docker_client is None:
        _docker_client = docker.from_env(version=version)
    return _docker_client


def generate_container_name(execution_id, step_num):
    """
    generates a unique name to be used for the container of an execution
    """
    res = "exec-%d-step-%d" % (execution_id, step_num)
    return res


def generate_network_name(execution_id, step_num):
    """
    generates a unique name to be used for the network of a Docker program execution
    """
    res = "network-for-exec-%d-step-%d" % (execution_id, step_num)
    return res


def check_if_container_is_active(container_name):
    """
    Returns a boolean indicating whether or not a RUNNING container of the given name exists.
    NOTE:
    This functions is a crutch. Theoretically, the field container.status should just tell us the status.
    But it seems to be bugged.
    So I use the console to figure out the status instead.
    """
    cmd = ['docker', 'ps', '--no-trunc', '--filter', 'name=^/%s$' % container_name]
    res = utilities.execute_terminal_command(cmd, get_output=True)
    res = (container_name in res)
    return res


def get_container_logs(container, number_of_log_lines):
    """
    Get the logs of a Docker container.
    """
    res = container.logs(stdout=True, stderr=True, tail=number_of_log_lines)
    res = res.decode("utf-8")
    return res


def execute_image(exec_env, image_name, path, execution_id, step_num, max_execution_duration, program_name, required_external_domains):
    """
    executes an existing Docker Image, optionally giving it access to a path to read and write from/to.
    The path should be specified in its entirety, not as a relative path.
    Instead of specifying the path directly, the ID of the execution (execution) and the number of the step within that execution (step) can be given,
    in which case the path is constructed from these parameters and the _the_manager.config['exec_env_root_folder'].
    Takes an optional time limit, measured in seconds.
    returns an error type as a string (or None if the program executed successfully), along with an error message.
    """
    # Raise exception if image_name is None
    if image_name is None:
        raise InvalidParamsException("This requested Program does not have a Docker Image associated with it. It looks like it was never uploaded successfully: %s" % program_name)
    # prepare parameters
    if path is None and execution_id is not None and step_num is not None:
        path = get_step_folder(execution_id, step_num)
    # connect to Docker
    client = get_docker_client()
    # define the folder mapping
    folder_mapping = {
        path : {
            'bind' : "/lod",
            'mode' : 'rw',
        },
    }
    # give the container a name
    container_name = generate_container_name(execution_id, step_num)
    # verify that a container with this name doesn't already exist
    # (this is mostly for debugging)
    try:
        client.containers.get(container_name)
        raise ServersideProgrammingError("This Docker Container already exists:\n%s" % container_name)
    except docker.errors.NotFound:
        pass
    # get the image
    try:
        client.images.get(image_name)
    except docker.errors.ImageNotFound:
        with CurrentlyDisplayedStatus(exec_env, "Downloading Program %s" % (program_name,)):
            client.images.pull(image_name)
    # If necessary, create a network to use
    # (Each Container runs on a separate network to prevent them accessing data in other Containers)
    # Note to developers: whenever you change this, also change the code in lod-tools used for testing a program locally.
    if len(required_external_domains) == 0:
        network_for_container = None
    else:
        if 'full_internet_access' not in required_external_domains:
            raise ServersideProgrammingError("Docker programs can currently only get internet access to the whole internet, not to only a few websites. This feature will be added later, by adding a complex proxy. This error should never be visible, because the server should not let it come to this point. If you see this error, please contact us.")
        network_name = generate_network_name(execution_id, step_num)
        network_for_container = client.networks.create(network_name, driver="bridge")
    # run the container in detached mode
    with CurrentlyDisplayedStatus(exec_env, "Running Program %s" % (program_name,)):
        # Use a network, or don't
        if network_for_container is None:
            container = client.containers.run(image=image_name, volumes=folder_mapping, name=container_name, detach=True, network_disabled=True)
        else:
            container = client.containers.run(image=image_name, volumes=folder_mapping, name=container_name, detach=True, network=network_name)
        # wait until either the time runs out or the container stops on its own or an external interrupt happens
        end_time = datetime.datetime.now() + datetime.timedelta(seconds=max_execution_duration)
        container_is_active = check_if_container_is_active(container_name)
        while datetime.datetime.now() < end_time \
                and container_is_active \
                and exec_env.interrupt_requested_for_program_execution_step != step_num \
                and not exec_env.signal_exec_env_shutdown.is_set():
            time.sleep(0.02)
            container_is_active = check_if_container_is_active(container_name)
    # if the container did not stop on its own, kill it
    error_type = None
    error_message = None
    if container_is_active:
        with CurrentlyDisplayedStatus(exec_env, "Timeout: interrupting current task..."):
            exec_env._print_message_if_verbose("Timeout: interrupting container %s of image %s" % (container_name, image_name,))
            try:
                container.kill()
            except Exception:
                pass
            if exec_env.interrupt_requested_for_program_execution_step == step_num \
                    or exec_env.signal_exec_env_shutdown.is_set():
                error_type = 'program_interrupted_from_outside'
                error_message = "Program was interrupted."
            else:
                error_type = 'program_timeout'
                error_message = "Program timed out after %s seconds." % (max_execution_duration,)
    # If there is no output file, use the logs of the container as an error message
    if not os.path.isfile(get_step_explanation_file_out(exec_env.id, step_num)):
        number_of_log_lines = 100
        error_log = get_container_logs(container, number_of_log_lines)
        error_type = 'program_docker_execution_failed'
        error_message = "Program failed to generate an output file. These are the last %d lines of logs:\n%s" % (number_of_log_lines, error_log,)
    # clean up by deleting the container and network, forcibly stopping it if that hasn't happened yet
    container.remove(force=True)
    if network_for_container is not None:
        network_for_container.remove()
    # return a code
    return error_type, error_message


###############################################################################################
# a manager, to handle multiple execution environments in parallel
# and let them all communicate with the outside
###############################################################################################


_the_manager = None
def initialize_execution_environment_manager(*args, **kwargs):
    """
    returns the manager for handling all execution environments.
    """
    global _the_manager
    _the_manager = ExecEnvManager(*args, **kwargs)


class ExecEnvManager(threading.Thread):
    """
    a manager, to handle multiple execution environments in parallel
    and let them all communicate with the outside.
    (NOTE: this is not very important so long as this file is in fact run on the same server as the main website,
    but it will be important once this is moved into a VM)
    """
    def __init__(self, config, truth, args):
        threading.Thread.__init__(self)
        # parameters
        self.config = config
        self.truth = truth
        self.args = args
        # variables
        self.execution_environments = {}
        # threading
        self.lock = threading.RLock()
    def initialize_execution_environment(self, exec_env_config):
        """
        This is called by the server.
        Creates a new ExecEnv locally, using the parameters received from the server.
        """
        execution_environment_id = exec_env_config['execution_environment_id']
        owner_id = exec_env_config['owner_id']
        starting_events = exec_env_config['starting_events']
        # create the ExecEnv and add it to the list
        exec_env = ExecEnv(execution_environment_id, owner_id, starting_events)
        with self.lock:
            if execution_environment_id in self.execution_environments:
                # the ExecEnv already exists
                # this is weird because it shouldn't happen, but is not really harmful. Issue a warning.
                error_message = "An ExecEnv with ID %d has already been initialized." % (execution_environment_id,)
                utilities.debugging_message('initialize-exec-env', "Warning: " + error_message)
                res = {
                    'success' : True,
                }
                return res
            else:
                utilities.debugging_message('initialize-exec-env', "started ExecEnv: %d" % execution_environment_id)
            self.execution_environments[execution_environment_id] = exec_env
            utilities.debugging_message('initialize-exec-env', "number of active ExecEnv threads: %d" % len(self.execution_environments.items()))
        # start it
        exec_env.daemon = True # this needs to be a Daemon so that KeyboardInterrupt works
        exec_env.start()
        exec_env.print_error_if_there_was_one()
        # response
        res = {
            'success' : True,
        }
        return res
    def shut_down_and_wait(self):
        """
        shut down all ExecEnvs and wait until they have all stopped running.
        """
        with self.lock:
            utilities.debugging_message('management', "shutting down all ExecEnvs.")
            registered_exec_envs = [(a,b) for a,b in self.execution_environments.items()]
            for exec_env_id, thread in registered_exec_envs:
                with thread.lock:
                    utilities.debugging_message('management', "shutting down ExecEnv %d." % (exec_env_id,))
                    self.shut_down_execution_environment(exec_env_id)
            # (note that this also waits on other threads than the one that has just been shut down:
            # this is because ExecEnvs that get shut down normally do not get joined()
            # so it could happen that an ExecEnv was told to shut down before this function was called but has not actually finished running yet.)
            active_exec_envs = [a for a in threading.enumerate() if isinstance(a, ExecEnv)]
            utilities.debugging_message('management', "waiting for %d threads to clean up after themselves." % (len(active_exec_envs),))
            for exec_env in active_exec_envs:
                exec_env.join()
            utilities.debugging_message('management', "done.")
    def shut_down_idle_exec_envs(self):
        """
        close ExecEnvs that have no incoming requests for too long (this happens if the Scenario has been closed but not properly shut down by the user)
        This function restarts itself so that it is called every few seconds.
        """
        with self.lock:
            for exec_env_id, thread in [(a,b) for a,b in self.execution_environments.items()]:
                with thread.lock:
                    timeout_in_seconds = self.truth['lod_executor_exec_env_timeout']
                    if thread.time_of_last_request + datetime.timedelta(seconds=timeout_in_seconds) < datetime.datetime.now():
                        utilities.debugging_message('management', "ExecEnv %d has timed out because there are no incoming requests for it. Shutting it down." % (exec_env_id,))
                        self.shut_down_execution_environment(exec_env_id)
    def shut_down_execution_environment(self, execution_environment_id, wait_until_done=False):
        """
        requests the controlled shut down of an ExecEnv.
        """
        try:
            with self.lock:
                exec_env = self.execution_environments.get(execution_environment_id, None)
                if exec_env is None:
                    utilities.debugging_message('shutdown-exec-env', "can't shut down ExecEnv that is already shut down: %d" % execution_environment_id)
                    res = {
                        'success' : False,
                        'message' : "the requested execution environment's Thread is no longer available. Presumably it has been shut down already."
                    }
                    return res
                else:
                    utilities.debugging_message('shutdown-exec-env', "shutting down ExecEnv: %d" % execution_environment_id)
                # request a shut down
                exec_env.request_controlled_shutdown(join=wait_until_done)
                # remove the reference to this ExecEnv, since it is no longer needed.
                # (garbage collection should remove the ExecEnv thread after it has stopped running and cleaned up after itself)
                del self.execution_environments[execution_environment_id]
                utilities.debugging_message('shutdown-exec-env', "number of active ExecEnv threads: %d" % len(self.execution_environments.items()))
            # respond
            res = {
                'success' : True,
            }
            return res
        except Exception:
            error_message = utilities.get_error_message_details()
            # respond
            res = {
                'success' : False,
                'error_message' : "an error occurred trying to shut down the execution environment:\n%s" % (error_message,)
            }
            return res
    def get_status_updates(self, execution_environment_id, *args, **kwargs):
        """
        ask the ExecEnv for a status update
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            # if exec_env is None, the ExecEnv must have been shut down and removed already
            shut_down_notification_event = {
                'is_extraordinary_event' : True,
                'type' : 'shut_down',
            }
            res = {
                'success' : True,
                'event_list' : [shut_down_notification_event],
                'current_status' : "The scenario has been shut down.",
            }
        else:
            # get a list of all status updates matching the parameters and return them
            res = exec_env.get_status_updates(*args, **kwargs)
        return res
    def submit_user_event(self, execution_environment_id, event_type=None, args={}):
        """
        tell the ExecEnv that a new event has been submitted by the user.
        Returns a dictionary denoting success or failure.
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            response_data = {
                'success' : False,
                'error_message' : "the execution environment %d has already been shut down" % execution_environment_id,
            }
        else:
            exec_env.submit_user_event(event_type=event_type, args=args)
            response_data = {
                'success' : True,
            }
        return response_data
    def handle_control_command(self, execution_environment_id, cmd, args):
        """
        tell the ExecEnv to process a command that changes the control flow of the ExecEnv
        or performs other changes that do not involve creating an Event for the server.
        Returns a dictionary denoting success or failure.
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            response_data = {
                'success' : False,
                'error_message' : "the execution environment %d has already been shut down" % execution_environment_id,
            }
        else:
            response_data = exec_env.handle_control_command(cmd, args)
        return response_data
    def process_message_from_scenario(self, request_data):
        """
        processes a message from a scenario and tells the ExecEnvManager about it.
        """
        message_type = request_data['message_type']
        message_dict = request_data['message_dict']
        execution_environment_id = request_data['execution_environment_id']
        # perform the right operation depending on the received message
        if message_type == 'get_update':
            next_io_event_index = message_dict['next_io_event_index']
            response_data = self.get_status_updates(execution_environment_id, next_io_event_index)
        elif message_type == 'user_command':
            # NOTE:
            # we assume that the files that have been uploaded according to message_dict can be found in the locations specified by message_dict
            # --
            # tell the ExecEnvManager to handle the user command
            response_data = self.submit_user_event(execution_environment_id, 'user_command', message_dict)
        elif message_type == 'embedded_website_command':
            response_data = self.submit_user_event(execution_environment_id, 'embedded_website_command', message_dict)
        elif message_type == 'select_option_for_execution':
            # tell the ExecEnvManager to handle the selected option
            response_data = self.submit_user_event(execution_environment_id, 'execute_option', message_dict)
        elif message_type == 'interrupt-program-execution':
            response_data = self.handle_control_command(execution_environment_id, 'interrupt-program-execution', message_dict)
        elif message_type == 'pause':
            response_data = self.handle_control_command(execution_environment_id, 'pause', message_dict)
        elif message_type == 'resume':
            response_data = self.handle_control_command(execution_environment_id, 'resume', message_dict)
        elif message_type == 'pseudo-download-file':
            response_data = self.handle_control_command(execution_environment_id, 'pseudo-download-file', message_dict)
        elif message_type == 'initialize_exec_env':
            exec_env_config = message_dict['exec_env_config']
            self.initialize_execution_environment(exec_env_config)
            response_data = {
                'success' : True,
            }
        elif message_type == 'shutdown_exec_env':
            response_data = self.shut_down_execution_environment(execution_environment_id)
        else:
            response_data = {
                'success' : False,
                'error_message' : "unknown message_type: '%s'" % message_type,
            }
        return response_data


###############################################################################################
# the execution environment class
###############################################################################################


class ExecEnv(threading.Thread):
    """
    this class corresponds to the models.ExecutionEnvironment class on the server.
    It runs on its own thread, in an endless loop, and communicates with the server.
    It performs Docker executions locally when the server requests it, and provides the server with event requests from the outside.
    """
    def __init__(self, execution_environment_id, owner_id, starting_events):
        threading.Thread.__init__(self)
        # constants
        self.id = execution_environment_id
        self.owner_id = owner_id # the user who created the ExecEnv
        # variables
        self.incoming_user_events = []
        self.status_updates = []
        self.number_of_objects_registered_for_status_updates = 0
        self.number_of_steps_registered_for_status_updates = 0
        self.current_status_message = "Starting..."
        self.current_local_event = None
        self.latest_object_manager = basics.ObjectManager(execution_environment_id)
        # threading
        self.time_of_last_request = datetime.datetime.now()
        self.lock = threading.RLock()
        self.interrupt_requested_for_program_execution_step = -1
        self.wait_for_resume_command_from_outside = threading.Event()
        self.wait_for_resume_command_from_outside.set()
        self.wait_for_input_from_outside = threading.Event()
        self.has_finished = threading.Event()
        self.has_error = threading.Event()
        self.signal_exec_env_shutdown = threading.Event()
        self.error = None
        # initialize
        for starting_event in starting_events:
            self.submit_user_event(starting_event['type'], starting_event['args'])
    ###############################################################################################
    # multithreading - these functions should be called from outside this thread
    ###############################################################################################
    def run(self):
        """
        keep running in an endless loop, until you are requested to stop
        """
        try:
            with CurrentlyDisplayedStatus(self, "Running..."):
                while not self.signal_exec_env_shutdown.is_set():
                    self._next_iteration()
            with self.lock:
                self.current_status_message = "Shut down."
        except Exception as e:
            with self.lock:
                self.error = sys.exc_info()
                error_message = utilities.get_error_message_details(self.error)
                error_message = "encountered an error on the lod-executor that was handling this Scenario:\n%s" % (error_message,)
            self.has_error.set()
            is_benign_error = isinstance(e, BenignException)
            # print the error, unless it was a benign one (i.e. an exception that while suboptimal is nothing to be concerned about)
            # in that case, just shut down the ExecEnv but don't report this.
            # (there is one benign exception, which is as follows:
            # the ExecutionEnvironment has already been shut down but the local ExecEnv has not noticed this yet.
            # A request by the ExecEnv has been rebuked by the server, resulting in a BenignException.)
            if not is_benign_error:
                # print the error
                self.print_error_if_there_was_one()
                # display the error on the scenarion if debug_mode is enabled
                if not _the_manager.config['debug_mode']:
                    error_message = "An error occurred. Activate debug mode on the lod-executor for details."
                status_update = {
                    'type' : 'exec_env_error',
                    'error_message' : error_message,
                }
                self._add_status_update(status_update)
        finally:
            self.has_finished.set()
    def submit_user_event(self, event_type, args):
        """
        add a new event to the ExecEnv.
        Returns a dictionary denoting success or failure.
        """
        event = basics.Event(basics.create_preliminary_identifier('event') , event_type, args=args, priority=False).to_json()
        with self.lock:
            self.incoming_user_events.append(event)
        # if this thread is waiting for a signal from outside, give that signal
        self.wait_for_input_from_outside.set()
    def handle_control_command(self, cmd, args):
        """
        process a command that changes the control flow of the ExecEnv
        or performs other changes that do not involve creating an Event for the server.
        Returns a dictionary denoting success or failure.
        """
        if cmd == 'interrupt-program-execution':
            step_of_execution_event = args['step_of_execution_event']
            self.interrupt_requested_for_program_execution_step = step_of_execution_event
            res = {
                'success' : True,
            }
        elif cmd == 'pause':
            self.wait_for_resume_command_from_outside.clear()
            # this res can be ignored. The actual status_update denoting the pause/resume will be created when the ExecEnv actually starts/stops waiting.
            res = {
                'success' : True,
            }
        elif cmd == 'resume':
            self.wait_for_resume_command_from_outside.set()
            # this res can be ignored. The actual status_update denoting the pause/resume will be created when the ExecEnv actually starts/stops waiting.
            res = {
                'success' : True,
            }
        elif cmd == 'pseudo-download-file':
            file_id = args['file_id']
            # get the file's location
            file_identifier = basics.Identifier(file_id, 'file')
            file_object = self.latest_object_manager.get_object_for_identifier(file_identifier)
            file_path_src = get_step_file_out(self.id, file_object.creation_step, file_object.creation_index)
            file_path_dst = args['destination_path']
            # check if the file exists
            if not os.path.isfile(file_path_src):
                return {
                    'success' : True,
                    'copying_succeeded' : False,
                    'error_message' : "The file can't be copied because it does not exist. It is possible that the file was registered without actually being created."
                }
            # check that the destination's parent exists, but that the destination itself either doesn't exist or is a file
            # (it's fine to overwrite a file, but if this is going to overwrite a folder that's could potentially be a very costly error on the user's side)
            file_path_dst_parent = os.path.dirname(file_path_dst)
            if not os.path.isdir(file_path_dst_parent):
                return {
                    'success' : True,
                    'copying_succeeded' : False,
                    'error_message' : "The directory of the destination does not exist."
                }
            if os.path.isdir(file_path_dst):
                return {
                    'success' : True,
                    'copying_succeeded' : False,
                    'error_message' : "There already exists a directory at the destination."
                }
            # try to copy the file to the destination
            try:
                shutil.copyfile(file_path_src, file_path_dst)
            except:
                response_data = {
                    'success' : True,
                    'copying_succeeded' : False,
                    'error_message' : "Failed to copy the file.",
                }
            res = {
                'success' : True,
                'copying_succeeded' : True,
            }
        else:
            res = {
                'success' : False,
                'error_message' : "a control command of this type does not exist: '%s'" % cmd,
            }
        return res
    def request_controlled_shutdown(self, join=False):
        """
        requests this execution environment to shut down.
        Optionally, joins on this and waits until it is done.
        NOTE: The ExecEnv will still finish its current iteration first, which could take a while depending on what it is currently doing.
        """
        self.signal_exec_env_shutdown.set()
        self.wait_for_resume_command_from_outside.set()
        self.wait_for_input_from_outside.set()
        if join:
            self.join(timeout=None)
    def get_status_updates(self, next_io_event_index):
        """
        get a list of status updates, starting at next_io_event_index,
        as well as the current status, as a text.
        """
        with self.lock:
            if len(self.status_updates) <= next_io_event_index:
                event_list = []
            else:
                event_list = self.status_updates[next_io_event_index:]
            current_local_event = self.current_local_event
            current_status = self.latest_object_manager.get_current_status_message()
            if current_status is None:
                current_status = self.current_status_message
            res = {
                'success' : True,
                'event_list' : event_list,
                'current_status' : current_status,
                'current_status_technical' : self.current_status_message, # this is not currently used, but it's a way to ignore !set_status_message tags if you want
                'current_local_event' : current_local_event,
            }
            # remember the time of this request
            self.time_of_last_request = datetime.datetime.now()
            return res
    def print_error_if_there_was_one(self):
        """
        DEBUGGING FUNCTION
        if there was an error, prints and returns it.
        This can be used to inspect this Thread from the outside.
        """
        with self.lock:
            if self.error is not None:
                error_msg = "exception inside ExecEnv Thread %s:\n" % (self.id,)
                error_msg += utilities.get_error_message_details(self.error)
                utilities.debugging_message('error', error_msg)
                return self.error
    def _print_message_if_verbose(self, message):
        """
        DEBUGGING FUNCTION
        prints a message if this program is running in verbose mode.
        """
        if _the_manager.args.verbose:
            msg = "ExecEnv %d: %s" % (self.id, message,)
            print(msg)
    ###############################################################################################
    # actual logic
    ###############################################################################################
    def _add_status_update(self, update_dict):
        """
        update the list of status updates, which can be queried from the outside.
        Adds one item to the list.
        """
        with self.lock:
            update_dict['status_index'] = len(self.status_updates)
            self.status_updates.append(update_dict)
    def _add_new_status_updates_of_object_manager(self, object_manager):
        """
        update the list of status updates, which can be queried from the outside.
        This works by creating one status_update per step header and one per object in the object_manager.
        Also updates the latest_object_manager.
        """
        all_objects = object_manager.get_all_objects()
        new_status_updates = []
        def _add_new_objects_for_current_step_header():
            step = self.number_of_steps_registered_for_status_updates - 1
            while self.number_of_objects_registered_for_status_updates < len(all_objects):
                obj = all_objects[self.number_of_objects_registered_for_status_updates]
                obj_step = object_manager.get_step_number_of_addition(obj.identifier)
                if step != obj_step:
                    break
                object_status_update = {
                    'type' : 'object_generated',
                    'step_that_generated_this_object' : step,
                    'object_type' : obj.identifier.type,
                    'status_object' : obj.to_json(),
                }
                self.number_of_objects_registered_for_status_updates += 1
                new_status_updates.append(object_status_update)
        # add all objects that were newly added and still belong to the last step header
        _add_new_objects_for_current_step_header()
        # add new step headers and the objects belonging to them
        while len(object_manager._statistics_at_beginning_of_step) > self.number_of_steps_registered_for_status_updates:
            step_header_statistics = object_manager._statistics_at_beginning_of_step[self.number_of_steps_registered_for_status_updates]
            step_header_status_update = {
                'type' : 'step_header',
                'step' : self.number_of_steps_registered_for_status_updates,
                'step_header_statistics' : step_header_statistics,
            }
            self.number_of_steps_registered_for_status_updates += 1
            new_status_updates.append(step_header_status_update)
            # add all new objects
            _add_new_objects_for_current_step_header()
        # update the list
        with self.lock:
            for status_update in new_status_updates:
                self._add_status_update(status_update)
            # also update the latest_object_manager
            self.latest_object_manager = object_manager
    def _next_iteration(self):
        # if no event was given, use the default event
        event = self.current_local_event
        if event is None:
            event = {
                'local_event_type' : 'request_next_iteration',
                'args' : {},
            }
        elif event['local_event_type'] == 'request_next_iteration':
            raise ServersideProgrammingError("a new iteration should only be requested when there is no local event scheduled, not for any other reason.")
        # note that the selected event is currently being executed
        # but only report the arguments that are actually needed, since this can be a lot of data to transfer
        local_event_type = event['local_event_type']
        args = event['args']
        if local_event_type == 'execute_program':
            reported_args = {
                'step' : basics.parse_object_manager(args['object_manager']).get_current_step(),
                'program_identifier' : args['program_identifier'],
            }
        else:
            reported_args = {}
        self.current_local_event = {
            'type' : local_event_type,
            'args' : reported_args,
        }
        # if necessary, wait
        if not self.wait_for_resume_command_from_outside.is_set():
            self._print_message_if_verbose("received wait-command from user. Waiting for resume-command.")
            with CurrentlyDisplayedStatus(self, "Paused. Press resume button to continue."):
                # tell the website about the new state of things being paused or resumed.
                status_update = {
                    'type' : 'pause_or_resume',
                    'pause' : True,
                    'resume' : False,
                }
                self._add_status_update(status_update)
                # wait
                self.wait_for_resume_command_from_outside.wait()
                # tell the website about the new state of things being paused or resumed.
                status_update = {
                    'type' : 'pause_or_resume',
                    'pause' : False,
                    'resume' : True,
                }
                self._add_status_update(status_update)
            self._print_message_if_verbose("received resume-command from user. Stopped waiting and continued executing.")
        # execute the selected event
        self._print_message_if_verbose("starting event: %s" % (local_event_type,))
        if local_event_type == 'request_next_iteration':
            # ask the server for input
            server_response = self.message_to_server('requesting_next_iteration', {})
            self.process_server_response(server_response)
        elif local_event_type == 'wait_for_input':
            with CurrentlyDisplayedStatus(self, "Waiting for input."):
                results = self._event_wait_for_input()
            # tell the server
            server_response = self.message_to_server('done_waiting_for_input', results)
            self.process_server_response(server_response)
        elif local_event_type == 'execute_program':
            with CurrentlyDisplayedStatus(self, "Executing program..."):
                # execute a specified program
                object_manager = basics.parse_object_manager(args['object_manager'])
                event_identifier = basics.parse_identifier(args['event_identifier'])
                program_identifier = basics.parse_identifier(args['program_identifier'])
                event = object_manager.get_object_for_identifier(event_identifier)
                program = object_manager.get_object_for_identifier(program_identifier)
                docker_image_name = program.docker_image_name
                required_external_domains = program.required_external_domains
                input_arguments_dict = {}
                # get all arguments to use for the program execution, both objects and lists of objects
                for k,v in event.args['argument_dict'].items():
                    input_arguments_dict[k] = object_manager.get_object_for_identifier(basics.parse_identifier(v))
                for k,vs in event.args['argument_list_dict'].items():
                    input_arguments_dict[k] = [object_manager.get_object_for_identifier(basics.parse_identifier(v)) for v in vs]
                max_execution_duration = args['max_execution_duration']
                # execute
                results = self._event_program_execution(object_manager, event_identifier, program_identifier,
                    docker_image_name, input_arguments_dict, max_execution_duration, required_external_domains)
            # tell the server about the results
            server_response = self.message_to_server('results_of_execution', results)
            self.process_server_response(server_response)
        elif local_event_type == 'confirm_file_upload':
            with CurrentlyDisplayedStatus(self, "Processing uploaded data..."):
                current_step = args['current_step']
                command_text = args['command_text']
                files_dict = args['files_dict']
                if files_dict is None:
                    files_dict = {}
                # make uploaded files available
                results = self._event_make_uploaded_files_available(command_text, files_dict, current_step)
            # tell the server about the results
            server_response = self.message_to_server('finished_uploading_files', results)
            self.process_server_response(server_response)
        elif local_event_type == 'prepare_for_import_of_existing_object':
            with CurrentlyDisplayedStatus(self, "Importing data..."):
                current_step = args['current_step']
                exporting_exec_env_id = args['exporting_exec_env_id']
                extracted_objects_file_dicts = args['extracted_objects_file_dicts']
                # Copy existing files from an older ExecEnv to make them available
                results = self._event_make_files_from_older_exec_env_available(current_step, exporting_exec_env_id, extracted_objects_file_dicts)
            # tell the server about the results
            server_response = self.message_to_server('finished_preparation_for_import_of_existing_object', results)
            self.process_server_response(server_response)
        elif local_event_type == 'execute_option_create_parameter_file':
            # create a file with a simple content
            # Note: the way this file is created is a bit irregular, but not harmful as of now. It couldn't hurt to refactor it later, though:
            # -the parameter file's FileObjectModel is created before the lod-executor is actually informed to create the file.
            # -the file is created as an output object of this iteration, even though it could theoretically also be used as an input in the same iteration
            # (in practice, that won't actually happen as the only action an Option can execute that uses a file (as of the time of this writing)
            # is a program_execution, which will only happen in a later step)
            parameter_file = basics.parse_file_object(args['parameter_file'])
            additional_parameters_selected_by_user = args['additional_parameters_selected_by_user']
            self._event_create_file_with_option_parameters_selected_by_user(parameter_file, additional_parameters_selected_by_user)
            # set the self.current_local_event to None, so this doesn't get called a second time
            self.current_local_event = None
        else:
            raise ServersideProgrammingError("an event of this type does not exist or is not handled yet: %s" % local_event_type)
    def _event_wait_for_input(self):
        """
        wait for user input
        """
        self.wait_for_input_from_outside.clear()
        # to avoid race conditions, verify that no user input has arrived in the meantime
        with self.lock:
            if len(self.incoming_user_events) != 0:
                self.wait_for_input_from_outside.set()
        self._print_message_if_verbose("start waiting for input from user")
        self.wait_for_input_from_outside.wait()
        self._print_message_if_verbose("end waiting for input from user")
        return {}
    def _event_program_execution(self, object_manager, event_identifier, program_identifier, docker_image_name, input_arguments_dict, max_execution_duration, required_external_domains):
        """
        get a program to execute and a list of arguments to use from an event and execute them.
        """
        if program_identifier.type != 'program':
            raise ServersideProgrammingError("""only program identifiers should be used here. This exception should never happen:
                this scenario should have been filtered out at an earlier point.""")
        # prepare the new step for its execution
        self._print_message_if_verbose("preparing step %d" % object_manager.get_current_step())
        with CurrentlyDisplayedStatus(self, "Preparation..."):
            self._prepare_step_for_execution(object_manager, event_identifier, program_identifier, input_arguments_dict)
        # execute the image
        self._print_message_if_verbose("executing Docker Image '%s'" % docker_image_name)
        with CurrentlyDisplayedStatus(self, "Program execution..."):
            try:
                error_type, error_message = execute_image(self, docker_image_name, None, self.id,
                    object_manager.get_current_step(), max_execution_duration, program_identifier.name, required_external_domains)
                if error_type is not None:
                    results_of_iteration = {
                        'error' : {
                            'error_type' : error_type,
                            'error_message' : error_message,
                        },
                    }
                    return results_of_iteration
            except Exception:
                error_message = utilities.get_error_message_details()
                results_of_iteration = {
                    'error' : {
                        'error_type' : 'program_docker_execution_failed',
                        'error_message' : error_message,
                    },
                }
                return results_of_iteration
        # attempt to parse the results
        self._print_message_if_verbose("parsing results of step %d" % object_manager.get_current_step())
        with CurrentlyDisplayedStatus(self, "Parsing results..."):
            try:
                execution_encountered_error, execution_output_dictionary_or_error_file_content = self._parse_results_of_step_after_execution(object_manager)
                if execution_encountered_error:
                    error_file_content = execution_output_dictionary_or_error_file_content
                    results_of_iteration = {
                        'error' : {
                            'error_type' : 'program_failed_with_error_file',
                            'error_message' : "content of error file generated by the program %s:\n%s" % (program_identifier.name, error_file_content,)
                        },
                    }
                    return results_of_iteration
            except Exception:
                error_message = utilities.get_error_message_details()
                results_of_iteration = {
                    'error' : {
                        'error_type' : 'program_result_parsing_failed',
                        'error_message' : error_message,
                    },
                }
                return results_of_iteration
        # return the information you want to send to the server
        execution_output_dictionary = execution_output_dictionary_or_error_file_content
        results_of_iteration = {
            'execution_output_dictionary' : execution_output_dictionary,
        }
        return results_of_iteration
    def _prepare_step_for_execution(self, object_manager, event_identifier, program_identifier, input_arguments_dict):
        """
        creates a folder to run a container from and prepares it with the correct data for input.
        the input_arguments_dict are a dict mapping argument names to objects and lists of objects, some of which are FileObjects the corresponding files of which need to be made available to the program.
        the input is:
        -one file called in.txt
        -one file per input, named "in_<output_index>"
        Also changes the input_file_objects by calling change_file_name_for_use_as_input() on them to change their file names.
        """
        step_folder = get_step_folder(self.id, object_manager.get_current_step())
        # recreate the folder if it already exists
        # outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        # (it doesb't hurt to leave this code in, though.)
        if os.path.exists(step_folder):
            shutil.rmtree(step_folder)
        os.makedirs(step_folder)
        with open(get_step_explanation_file_in(self.id, object_manager.get_current_step()), 'w', encoding='utf8') as f:
            input_description = {}
            input_description['object_manager'] = object_manager.to_json()
            input_description['event_identifier'] = event_identifier.to_json()
            input_description['program_identifier'] = program_identifier.to_json()
            # create a dict of arguments that the lod-library can read and remember the FileObjects among them for later in this function
            program_arguments_dict = {}
            input_file_objects = []
            for k,v in input_arguments_dict.items():
                if isinstance(v, list):
                    program_arguments_dict[k] = [a.identifier.to_json() for a in v]
                    input_file_objects.extend(a for a in v if isinstance(a, basics.FileObject))
                else:
                    program_arguments_dict[k] = v.identifier.to_json()
                    if isinstance(v, basics.FileObject):
                        input_file_objects.append(v)
            input_description['arguments'] = program_arguments_dict
            input_description['input_file_object_identifiers'] = [a.identifier.to_json() for a in input_file_objects]
            json.dump(input_description, f, indent=4, ensure_ascii=False)
        # copy the input files from the location where they were created to the new folder where they will be used for the planned program execution
        for arg_index, file_object in enumerate(input_file_objects):
            if file_object.creation_step >= object_manager.get_current_step():
                raise ServersideProgrammingError("Objects used in an execution must be from an earlier step")
            from_file = get_step_file_out(self.id, file_object.creation_step, file_object.creation_index)
            to_file = get_step_file_in(self.id, object_manager.get_current_step(), arg_index)
            shutil.copyfile(from_file, to_file)
    def _parse_results_of_step_after_execution(self, object_manager):
        """
        reads a folder that has been operated on by an execute_image() operation.
        Returns an object describing the results of that operation.
        """
        error_file = get_step_file_error(self.id, object_manager.get_current_step())
        if os.path.exists(error_file):
            with open(error_file, 'r') as f:
                execution_output_dictionary_or_error_file_content = f.read()
            self._print_message_if_verbose("WARNING: step %d generated an error file!" % object_manager.get_current_step())
            execution_encountered_error = True
        else:
            execution_encountered_error = False
            with open(get_step_explanation_file_out(self.id, object_manager.get_current_step()), 'r', encoding='utf8') as f:
                execution_output_dictionary_or_error_file_content = json.load(f)
        return execution_encountered_error, execution_output_dictionary_or_error_file_content
    def _event_make_uploaded_files_available(self, command_text, files_dict, current_step):
        """
        process a command from the user to make uploaded files available in the current_step.
        """
        step_folder = get_step_folder(self.id, current_step)
        # recreate the folder if it already exists
        # outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        # (it doesb't hurt to leave this code in, though.)
        if os.path.exists(step_folder):
            shutil.rmtree(step_folder)
        # create the folder if it doesn't exist yet
        os.makedirs(step_folder)
        creation_index = 0
        created_file_object_for_command = None
        if command_text is not None:
            # create the file and write the text into it
            full_file_name = get_step_file_out(self.id, current_step, creation_index)
            with open(full_file_name, 'w') as f:
                f.write(command_text)
            # create a preliminary file object for it
            preliminary_identifier = basics.create_preliminary_identifier('file')
            creation_step = None # dummy value, to be ignored by the server
            file_name = "user_command.txt"
            created_file_object_for_command = basics.FileObject(preliminary_identifier, file_name, creation_step, creation_index)
            creation_index += 1
        created_file_objects_for_files = []
        for file_name, uploaded_file_temporary_storage_name in files_dict.items():
            try:
                # copy the file from its temporary storage to its new destination
                full_file_name = get_step_file_out(self.id, current_step, creation_index)
                shutil.copyfile(uploaded_file_temporary_storage_name, full_file_name)
                # create a preliminary file object for it
                preliminary_identifier = basics.create_preliminary_identifier('file')
                creation_step = None # dummy value, to be ignored by the server
                created_file_objects_for_files.append(basics.FileObject(preliminary_identifier, file_name, creation_step, creation_index))
                creation_index += 1
            except:
                # NOTE: this error should only occur if a user is using a local lod-executor and enters a file name incorrectly
                results = {
                    'error' : {
                        'error_type' : 'file_copying_failed',
                        'error_message' : 'Failed to copy the file at this location: "%s"' % (uploaded_file_temporary_storage_name,),
                    }
                }
                return results
        # return
        results = {
            'command_text' : command_text,
            'created_file_object_for_command' : None if created_file_object_for_command is None else created_file_object_for_command.to_json(),
            'created_file_objects_for_files' : [a.to_json() for a in created_file_objects_for_files],
        }
        return results
    def _event_make_files_from_older_exec_env_available(self, current_step, exporting_exec_env_id, extracted_objects_file_dicts):
        """
        Make files from an older ExecEnv on this lod-executor available in the current_step, as part of the process of importing an object.
        """
        dst_step_folder = get_step_folder(self.id, current_step)
        # recreate the folder if it already exists
        # outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        # (it doesb't hurt to leave this code in, though.)
        if os.path.exists(dst_step_folder):
            shutil.rmtree(dst_step_folder)
        # create the folder if it doesn't exist yet
        os.makedirs(dst_step_folder)
        # Copy the files
        creation_index = 0
        old_file_id_to_new_file_dict = {}
        for existing_file_identifier_dict in extracted_objects_file_dicts:
            src_file = get_step_file_out(exporting_exec_env_id, existing_file_identifier_dict['creation_step'], existing_file_identifier_dict['creation_index'])
            dst_file = get_step_file_out(self.id, current_step, creation_index)
            try:
                # copy the file from its current storage to its new destination
                shutil.copyfile(src_file, dst_file)
                # create a preliminary file object for it
                preliminary_identifier = basics.create_preliminary_identifier('file')
                creation_step = None # dummy value, to be ignored by the server
                file_name = existing_file_identifier_dict['file']
                old_file_id_to_new_file_dict[existing_file_identifier_dict['identifier']['id']] = basics.FileObject(preliminary_identifier, file_name, creation_step, creation_index).to_json()
                creation_index += 1
            except:
                # NOTE: this error should only occur if a user is using a local lod-executor and enters a file name incorrectly
                results = {
                    'error' : {
                        'error_type' : 'file_copying_failed',
                        'error_message' : 'Failed to copy the file at this location: "%s"' % (src_file,),
                    }
                }
                return results
        # Return
        results = {
            'old_file_id_to_new_file_dict' : old_file_id_to_new_file_dict,
        }
        return results
    def _event_create_file_with_option_parameters_selected_by_user(self, parameter_file, additional_parameters_selected_by_user):
        """
        create a file with a given content
        """
        step_folder = get_step_folder(self.id, parameter_file.creation_step)
        # recreate the folder if it already exists
        # outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        # (it doesb't hurt to leave this code in, though.)
        if os.path.exists(step_folder):
            shutil.rmtree(step_folder)
        # create the folder if it doesn't exist yet
        os.makedirs(step_folder)
        # write the JSON object to the file
        file = get_step_file_out(self.id, parameter_file.creation_step, parameter_file.creation_index)
        with open(file, 'w', encoding='utf8') as f:
            json.dump(additional_parameters_selected_by_user, f, indent=4, ensure_ascii=False)
    def process_server_response(self, server_response):
        """
        process the decisions made by the server by adding new objects to this ExecEnv and scheduling local events.
        """
        self.current_local_event = server_response.get('next_local_event', None)
        if 'latest_object_manager' in server_response:
            # process any new status updates to display
            latest_object_manager = basics.parse_object_manager(server_response['latest_object_manager'])
            self._add_new_status_updates_of_object_manager(latest_object_manager)
        if server_response.get('an_error_occurred', False):
            is_benign_error = server_response['is_benign_error']
            # DEBUG
            # add a status message informing the user of the error
            # this is only for debugging and should not be enabled in a production setting
            error_message = server_response['error_message']
            # shut down the ExecEnv
            error_message = "encountered an unexpected error on the server:\n%s" % error_message
            if is_benign_error:
                raise BenignException(error_message)
            else:
                raise ServersideProgrammingError(error_message)
###############################################################################################
# functions for communicating with the server
###############################################################################################
    def message_to_server(self, message_type, args):
        """
        tells the server what this local ExecEnv has done.
        """
        with CurrentlyDisplayedStatus(self, "Thinking..."):
            with self.lock:
                message = {
                    'email' : _the_manager.config['email'],
                    'password' : _the_manager.config['password'],
                    'serverside_exec_env_recognition_key' : _the_manager.config['serverside_exec_env_recognition_key'],
                    'execution_environment_id' : self.id,
                    'message_type' : message_type,
                    'message_args' : args,
                    'incoming_user_events' : self.incoming_user_events,
                }
                self.incoming_user_events = []
            data = {
                'message' : json.dumps(message),
            }
            url = "%sexec_env/communicate/execution_environment/" % (_the_manager.config['server_contact_url'],)
            # note:
            # I needed to add 'SSLAdapter(ssl.PROTOCOL_TLSv1_2)' to make POST work again
            # after I gave the lod-executor its own certificates.
            # I'm not really sure why this was necessary, since the certificates I added changed the lod-executor's own behavior as a server
            # and should not have affected its ability to access another server, but it did.
            # It works now, but this could probably be improved by someone with a better understanding of SSL/HTTPS/etc than me.
            if _the_manager.config['server_contact_url'].startswith('https'):
                session = requests.Session()
                session.mount(_the_manager.config['server_contact_url'], SSLAdapter(ssl.PROTOCOL_TLSv1_2))
                resp = session.post(url, data=data)
            else:
                resp = requests.post(url, data=data)
            res = json.loads(resp._content.decode(_get_truth()['json_encoding']))
            return res
